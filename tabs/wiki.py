import streamlit as st
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np

def show_wiki():
    st.header("ğŸ“š í˜‘ì—… ê²Œì‹œíŒ")
    
    # ì„¸ì…˜ ìƒíƒœì— ì´ˆê¸° íƒœê·¸ ëª©ë¡ì´ ì—†ìœ¼ë©´ ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¡œ ì´ˆê¸°í™”
    if 'all_tags' not in st.session_state:
        st.session_state.all_tags = []
    
    # íƒœê·¸ ì¶”ì²œ (ë¹ˆë„ ê¸°ë°˜)
    tag_frequencies = {tag: 0 for tag in st.session_state.all_tags}
    for entry in st.session_state.get('wiki', []):
        for tag in entry['tags']:
            if tag in tag_frequencies:
                tag_frequencies[tag] += 1
    recommended_tags = sorted(tag_frequencies, key=tag_frequencies.get, reverse=True)[:5]
    
    # ìƒˆ íƒœê·¸ ì…ë ¥ í•„ë“œ
    st.subheader("ğŸ”– ìƒˆ íƒœê·¸ ì…ë ¥")
    new_tag = st.text_input("ìƒˆ íƒœê·¸ ì…ë ¥ (Enter í‚¤ë¡œ ì¶”ê°€)")
    if new_tag:
        if new_tag not in st.session_state.all_tags:
            st.session_state.all_tags.append(new_tag)
            st.success(f"íƒœê·¸ '{new_tag}' ì¶”ê°€ ì™„ë£Œ")
        else:
            st.warning("ì´ë¯¸ ì¡´ì¬í•˜ëŠ” íƒœê·¸ì…ë‹ˆë‹¤.")
        st.session_state['new_tag'] = ''
    
    # ì¶”ì²œ íƒœê·¸ ë²„íŠ¼
    if recommended_tags:
        st.write("ì¶”ì²œ íƒœê·¸:")
        for tag in recommended_tags:
            if st.button(tag):
                if tag not in st.session_state.all_tags:
                    st.session_state.all_tags.append(tag)
    
    st.markdown("---")
    
    # ìƒˆ ìœ„í‚¤ í•­ëª© ë“±ë¡
    st.subheader("âœ ìƒˆ í•­ëª© ë“±ë¡")
    author = st.text_input("ì‘ì„±ì ì´ë¦„")
    
    # íƒœê·¸ ì…ë ¥
    tags = st.multiselect(
        "íƒœê·¸ (ê¸°ì¡´ íƒœê·¸ ì„ íƒ ë˜ëŠ” ìƒˆ íƒœê·¸ ì…ë ¥ í›„ Enter)",
        options=st.session_state.all_tags,
        default=[],
        help="ê¸°ì¡´ íƒœê·¸ë¥¼ ì„ íƒí•˜ê±°ë‚˜ ìƒˆ íƒœê·¸ë¥¼ ì…ë ¥í•œ ë’¤ Enterë¥¼ ëˆŒëŸ¬ ì¶”ê°€í•˜ì„¸ìš”."
    )
    
    # ìœ„í‚¤ ë‚´ìš© ì…ë ¥ (ì˜ˆì‹œ í…œí”Œë¦¿ ì œê³µ)
    example_template = (
        "## ì œëª©\n\n"
        "### ê°œìš”\n\n"
        "- í•µì‹¬ ìš”ì•½\n"
        "- ì£¼ìš” í¬ì¸íŠ¸\n\n"
        "### ìƒì„¸ ë‚´ìš©\n\n"
        "1. ì²« ë²ˆì§¸ í•­ëª©\n"
        "2. ë‘ ë²ˆì§¸ í•­ëª©\n\n"
        "### ì°¸ê³  ìë£Œ\n\n"
        "- ë§í¬ 1\n"
        "- ë§í¬ 2\n"
    )
    content = st.text_area("ìœ„í‚¤ ë‚´ìš©", value=example_template, height=200)
    
    # ìœ„í‚¤ ì €ì¥
    if st.button("ì €ì¥"):
        if author and tags and content:
            new_entry = {'author': author, 'tags': tags, 'content': content}
            st.session_state.setdefault('wiki', []).append(new_entry)
            st.success("ìœ„í‚¤ ì €ì¥ ì™„ë£Œ")
        else:
            st.warning("ì‘ì„±ì ì´ë¦„, íƒœê·¸, ë‚´ìš©ì„ ëª¨ë‘ ì…ë ¥í•˜ì„¸ìš”.")
    
    st.markdown("---")
    
    # ê²Œì‹œíŒ ë‚´ ê²€ìƒ‰ ê¸°ëŠ¥
    st.subheader("ğŸ” ê²Œì‹œíŒ ê²€ìƒ‰")
    search_query = st.text_input("ê²€ìƒ‰ì–´ ì…ë ¥")
    
    # í•„í„° íƒœê·¸
    filter_tags = st.multiselect("í•„í„° íƒœê·¸", options=st.session_state.all_tags)
    
    # ê²€ìƒ‰ ë° í•„í„° ì ìš©
    wiki_data = st.session_state.get('wiki', [])
    if search_query:
        wiki_data = [w for w in wiki_data if search_query.lower() in w['content'].lower() or search_query.lower() in w['author'].lower()]
    if filter_tags:
        wiki_data = [w for w in wiki_data if any(tag in w['tags'] for tag in filter_tags)]
    
    # ìœ ì‚¬ í•­ëª© ë³‘í•© ì œì•ˆ
    if len(wiki_data) > 1:
        contents = [entry['content'] for entry in wiki_data]
        vectorizer = TfidfVectorizer().fit_transform(contents)
        similarities = cosine_similarity(vectorizer)
        np.fill_diagonal(similarities, 0)
        similar_pairs = np.argwhere(similarities > 0.8)
        
        if similar_pairs.size > 0:
            st.warning("ìœ ì‚¬ë„ê°€ ë†’ì€ í•­ëª©ì´ ìˆìŠµë‹ˆë‹¤. ë³‘í•©ì„ ê³ ë ¤í•´ ë³´ì„¸ìš”.")
            for i, j in similar_pairs:
                st.write(f"ìœ ì‚¬ í•­ëª©: [{wiki_data[i]['author']}]ì™€ [{wiki_data[j]['author']}] (ìœ ì‚¬ë„: {similarities[i, j]:.2f})")
    
    # ê²Œì‹œíŒ í‘œì‹œ
    st.subheader("ğŸ“‚ ê²Œì‹œíŒ ëª©ë¡")
    if wiki_data:
        for entry in wiki_data:
            st.markdown(
                f"""
                <div style="border: 1px solid #ddd; padding: 15px; border-radius: 5px; margin-bottom: 10px;">
                    <strong>ì‘ì„±ì</strong>: {entry['author']}<br />
                    <strong>íƒœê·¸</strong>: {', '.join(entry['tags'])}<br />
                    <strong>ë‚´ìš©</strong>:<br />{entry['content']}
                </div>
                """,
                unsafe_allow_html=True
            )
    else:
        st.info("ë“±ë¡ëœ í•­ëª©ì´ ì—†ìŠµë‹ˆë‹¤.")